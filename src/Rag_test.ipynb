{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d56f4ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## I will be testing my RAG pipeline \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0633914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/arthurkwakugregory/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from Retrival_phase import reset_database\n",
    "import requests\n",
    "from Retrival_phase import initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "572ee208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Risk_management.pdf', 'psychology_of_life.html']\n"
     ]
    }
   ],
   "source": [
    "def download_files():\n",
    "    sample_files = [\n",
    "\n",
    "        {\n",
    "            \"url\": \"https://www.ipcc.ch/site/assets/uploads/sites/4/2022/11/SRCCL_Chapter_7.pdf\",\n",
    "            \"file_name\": \"Risk_management.pdf\"\n",
    "        },\n",
    "\n",
    "        {\n",
    "            \"url\": \"https://medium.com/@kathrynmcm/the-surprising-psychology-of-life-without-mirrors-7d5011e53d94\",\n",
    "            \"file_name\": \"psychology_of_life.html\"  \n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for files in sample_files:\n",
    "        resp= requests.get(files[\"url\"])\n",
    "        with open(files[\"file_name\"], \"wb\") as f:\n",
    "            f.write(resp.content)\n",
    "    return [file_name[\"file_name\"] for file_name in sample_files]\n",
    "\n",
    "\n",
    "file_name= download_files()\n",
    "\n",
    "print(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d280bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502b7597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n",
      "the total  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m Vectors= \u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/arthurkwakugregory/Desktop/Git_Repos/RAG_From_Scratch/src/Risk_management.pdf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Git_Repos/RAG_From_Scratch/src/Retrival_phase.py:17\u001b[39m, in \u001b[36minitialize\u001b[39m\u001b[34m(file_name)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minitialize\u001b[39m(file_name):\n\u001b[32m     16\u001b[39m     file_type= file_name.split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] \n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_and_add_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Git_Repos/RAG_From_Scratch/src/Ingesting_phase.py:124\u001b[39m, in \u001b[36mDoc_Vectorizer.process_and_add_documents\u001b[39m\u001b[34m(self, file_path, file_type)\u001b[39m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou provided an incorrect file type\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    123\u001b[39m \u001b[38;5;28mself\u001b[39m.original_docs.append(original_data)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28mself\u001b[39m.vectors= \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vectors\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Git_Repos/RAG_From_Scratch/src/Ingesting_phase.py:109\u001b[39m, in \u001b[36mDoc_Vectorizer.add_documents\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[32m    108\u001b[39m     \u001b[38;5;28mself\u001b[39m.vectorized_docs.append(text)\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28mself\u001b[39m.vectors= \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorized_docs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vectors\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Git_Repos/RAG_From_Scratch/env/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:2104\u001b[39m, in \u001b[36mTfidfVectorizer.fit_transform\u001b[39m\u001b[34m(self, raw_documents, y)\u001b[39m\n\u001b[32m   2097\u001b[39m \u001b[38;5;28mself\u001b[39m._check_params()\n\u001b[32m   2098\u001b[39m \u001b[38;5;28mself\u001b[39m._tfidf = TfidfTransformer(\n\u001b[32m   2099\u001b[39m     norm=\u001b[38;5;28mself\u001b[39m.norm,\n\u001b[32m   2100\u001b[39m     use_idf=\u001b[38;5;28mself\u001b[39m.use_idf,\n\u001b[32m   2101\u001b[39m     smooth_idf=\u001b[38;5;28mself\u001b[39m.smooth_idf,\n\u001b[32m   2102\u001b[39m     sublinear_tf=\u001b[38;5;28mself\u001b[39m.sublinear_tf,\n\u001b[32m   2103\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2104\u001b[39m X = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2105\u001b[39m \u001b[38;5;28mself\u001b[39m._tfidf.fit(X)\n\u001b[32m   2106\u001b[39m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[32m   2107\u001b[39m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Git_Repos/RAG_From_Scratch/env/lib/python3.11/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Git_Repos/RAG_From_Scratch/env/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:1376\u001b[39m, in \u001b[36mCountVectorizer.fit_transform\u001b[39m\u001b[34m(self, raw_documents, y)\u001b[39m\n\u001b[32m   1368\u001b[39m             warnings.warn(\n\u001b[32m   1369\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mUpper case characters found in\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1370\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m vocabulary while \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlowercase\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1371\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m is True. These entries will not\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1372\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m be matched with any documents\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1373\u001b[39m             )\n\u001b[32m   1374\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1376\u001b[39m vocabulary, X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.binary:\n\u001b[32m   1379\u001b[39m     X.data.fill(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Git_Repos/RAG_From_Scratch/env/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:1263\u001b[39m, in \u001b[36mCountVectorizer._count_vocab\u001b[39m\u001b[34m(self, raw_documents, fixed_vocab)\u001b[39m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[32m   1262\u001b[39m     feature_counter = {}\n\u001b[32m-> \u001b[39m\u001b[32m1263\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1264\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1265\u001b[39m             feature_idx = vocabulary[feature]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Git_Repos/RAG_From_Scratch/env/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:104\u001b[39m, in \u001b[36m_analyze\u001b[39m\u001b[34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m         doc = \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    106\u001b[39m         doc = tokenizer(doc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Git_Repos/RAG_From_Scratch/env/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:62\u001b[39m, in \u001b[36m_preprocess\u001b[39m\u001b[34m(doc, accent_function, lower)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03mapply to a document.\u001b[39;00m\n\u001b[32m     45\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m \u001b[33;03m    preprocessed string\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     doc = \u001b[43mdoc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m()\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     64\u001b[39m     doc = accent_function(doc)\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "Vectors= initialize(\"/Users/arthurkwakugregory/Desktop/Git_Repos/RAG_From_Scratch/src/Risk_management.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b89fe55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
